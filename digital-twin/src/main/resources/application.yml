server:
  port: 8082

app:
  digital-twin:
    state-retention: 24h
    snapshot-interval: 5m
    anomaly-detection:
      mode: "threshold-based"  # Can switch to "ml-based" or "statistical"
      temperature-threshold: 85.0
      vibration-threshold: 3.0
      load-threshold: 95.0
      statistical-deviation-multiplier: 2.5
      threshold:
        enabled: true
      ml:
        enabled: false         # Enable when ready for ML
        model-path: "/models/"
        confidence-threshold: 0.8
      statistical:
        enabled: false         # Enable for statistical methods
        window-size: 100       # Number of readings for statistical analysis
    state-store:
      max-entries: 10000
      eviction-timeout: 1h

kafka:
  bootstrap-servers: localhost:9092
  consumer:
    group-id: digital-twin-group
    key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
    auto-offset-reset: latest
    enable-auto-commit: false
  producer:
   key-serializer: org.apache.kafka.common.serialization.StringSerializer
   value-serializer: org.springframework.kafka.support.serializer.JsonSerializer

spring:
  datasource:
    url: jdbc:postgresql://localhost:5432/digital_twin
    username: digital_twin_user
    password: ${POSTGRES_PASSWORD:password123}
    driver-class-name: org.postgresql.Driver
  jpa:
    hibernate:
      ddl-auto: validate  # Validate schema against entities, but don't update
    show-sql: false
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
        format_sql: true
  flyway:
    enabled: true
    locations: classpath:db/migration
    baseline-on-migrate: true
  kafka:
    consumer:
      bootstrap-servers: ${kafka.bootstrap-servers}
      group-id: ${kafka.consumer.group-id}
      key-deserializer: ${kafka.consumer.key-deserializer}
      value-deserializer: ${kafka.consumer.value-deserializer}
      auto-offset-reset: ${kafka.consumer.auto-offset-reset}
      enable-auto-commit: ${kafka.consumer.enable-auto-commit}
    producer:
      bootstrap-servers: ${kafka.bootstrap-servers}
      key-serializer: ${kafka.producer.key-serializer}
      value-serializer: ${kafka.producer.value-serializer}

management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics
  endpoint:
    health:
      show-details: when-authorized